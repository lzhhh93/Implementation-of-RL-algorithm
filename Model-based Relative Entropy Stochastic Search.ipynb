{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 5: Model-based Relative Entropy Stochastic Search (15 Pts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All homeworks are self-contained. They can be completed in their respective notebooks.\n",
    "To edit and re-run code, you can therefore simply edit and restart the code cells below.\n",
    "There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window).\n",
    "This file should automatically be synced with your Google Drive. We also save all recordings and logs in it by default so that you won't lose your work in the event of an instance timeout.\n",
    " However, you will need to re-mount your Google Drive and re-install packages with every new instance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your work will be stored in a folder called `drl_ws21` by default to prevent Colab\n",
    "# instance timeouts from deleting your edits.\n",
    "# We do this by mounting your google drive on the virtual machine created in this colab\n",
    "# session. For this, you will likely need to sign in to your Google account and copy a\n",
    "# passcode into a field below\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create paths in your google drive\n",
    "DRIVE_PATH = '/content/gdrive/My\\ Drive/drl_ws21'\n",
    "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
    "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
    "    % mkdir $DRIVE_PATH\n",
    "\n",
    "# the space in `My Drive` causes some issues,\n",
    "# make a symlink to avoid this\n",
    "SYM_PATH = '/content/drl_ws21'\n",
    "if not os.path.exists(SYM_PATH):\n",
    "    !ln -s $DRIVE_PATH $SYM_PATH\n",
    "% cd $SYM_PATH"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install **python** and **system** packages\n",
    "\n",
    "# install required python dependencies\n",
    "!pip install matplotlib numpy tqdm scipy nlopt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by importing all the necessary python modules and defining some helper\n",
    "functions which you do not need to change. Still, make sure you are aware of\n",
    "what they do."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports and utility\n",
    "# Progress bar\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import nlopt\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(0)\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, num_iterations: int, verbose: bool = True):\n",
    "        if verbose:  # create a nice little progress bar\n",
    "            self.scalar_tracker = tqdm.tqdm(total=num_iterations, desc=\"Scalars\", bar_format=\"{desc}\",\n",
    "                                            position=0, leave=True)\n",
    "            progress_bar_format = '{desc} {n_fmt:' + str(\n",
    "                len(str(num_iterations))) + '}/{total_fmt}|{bar}|{elapsed}<{remaining}'\n",
    "            self.progress_bar = tqdm.tqdm(total=num_iterations, desc='Iteration', bar_format=progress_bar_format,\n",
    "                                          position=1, leave=True)\n",
    "        else:\n",
    "            self.scalar_tracker = None\n",
    "            self.progress_bar = None\n",
    "\n",
    "    def __call__(self, _steps: int = 1, **kwargs):\n",
    "        if self.progress_bar is not None:\n",
    "            formatted_scalars = {key: \"{:.3e}\".format(value[-1] if isinstance(value, list) else value)\n",
    "                                 for key, value in kwargs.items()}\n",
    "            description = (\"Scalars: \" + \"\".join([str(key) + \"=\" + value + \", \"\n",
    "                                                  for key, value in formatted_scalars.items()]))[:-2]\n",
    "            self.scalar_tracker.set_description(description)\n",
    "            self.progress_bar.update(_steps)\n",
    "\n",
    "    def update(self, increment: int):\n",
    "        if self.progress_bar is not None:\n",
    "            self.progress_bar.update(increment)\n",
    "\n",
    "# specify the path to save the recordings of this run to.\n",
    "data_path = '/content/drl_ws21/exercise_5'\n",
    "data_path = os.path.join(data_path, time.strftime(\"%d-%m-%Y_%H-%M\"))\n",
    "if not (os.path.exists(data_path)):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "# this function will automatically save your figure into your google drive folder (if correctly mounted!)\n",
    "def save_figure(save_name: str) -> None:\n",
    "    assert save_name is not None, \"Need to provide a filename to save to\"\n",
    "    plt.savefig(os.path.join(data_path, save_name + \".png\"))\n",
    "\n",
    "\n",
    "def plot_metrics(metrics: Dict[str, List[float]]):\n",
    "    \"\"\"\n",
    "    Plots various metrics recorded during training\n",
    "    :param metrics:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(metrics) > 0:\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(16, 9))\n",
    "        for position, (key, value) in enumerate(metrics.items()):\n",
    "            plt.subplot(len(metrics), 1, position + 1)\n",
    "            plt.plot(range(len(value)), np.array(value))\n",
    "            plt.ylabel(key.title())\n",
    "        plt.xlabel(\"Recorded Steps\")\n",
    "        plt.tight_layout()\n",
    "        save_figure(f\"training_metrics\")\n",
    "        plt.clf()\n",
    "        plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Model-based Relative Entropy Stochastic Search (15 Pts)**\n",
    "\n",
    "This exercise is about Model-based Relative Entropy Stochastic Search (MORE), a gradient free policy search algorithm\n",
    "for blackbox function optimization.\n",
    "MORE makes use of a Gaussian search distribution with a full covariance matrix, and iteratively updates this distribution\n",
    "by\n",
    "* drawing samples from it\n",
    "* evaluating the samples on the target function\n",
    "* fitting a quadratic surrogate model on the samples and their targets\n",
    "* using this model to update the search distribution in closed form under entropy and KL constraints\n",
    "\n",
    "The algorithm is comparatively involved and contains a lot of details and complex expressions. As such, this exercise\n",
    "will not dive into the core algorithm too deeply. Instead, we will focus on small, individual parts of it\n",
    "as well as on some pen&paper tasks. You are of course still incentivized to look at it in more detail.\n",
    "\n",
    "For now, we will start by defining our task and then the individual parts, namely the Gaussian and the surrogate model\n",
    "that are needed for MORE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Point Reacher\n",
    "Our task for this exercise is a planar point reaching task. A robot arm starting at position $(0,0)^T$ with $n$ links\n",
    "of length $1$ is tasked to reach a point at positions $(0.7*n, 0)^T$.\n",
    "The action space consist of a continuous angle for each of the $n$ joints.\n",
    "To incentivize smooth solutions, there is an additional penalty term on the squared angles.\n",
    "\n",
    "You do **not** need to adapt the code for this task."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PointReacher:\n",
    "\n",
    "    def __init__(self, num_links: int, likelihood_std: float, smoothness_prior_std: Union[np.array, List[float]]):\n",
    "        \"\"\"\n",
    "        Initialization of a simple point reacher task, where the goal is to reach a point (0, num_links*0,7) using\n",
    "        a robot arm with num_links joints of length 1. Note that this task does *not* use time-series data, but\n",
    "        instead evaluates a single angle configuration.\n",
    "        :param num_links: Number of links of the robot\n",
    "        :param likelihood_std: The \"main\" reward (not regarding the smoothness prior) is the closeness to the point/line.\n",
    "            This reward is represented as a Gaussian with likelihood likelihood_std\n",
    "        :param smoothness_prior_std: Standard deviation of a zero-mean Gaussian acting in angle space.\n",
    "            Adds a smoothness prior for each joint, with smaller values leading to smoother solutions.\n",
    "        \"\"\"\n",
    "        self._num_links = num_links\n",
    "        self.target = [0.7 * num_links, 0]\n",
    "        self._smoothness_likelihood = multivariate_normal(np.zeros(num_links),\n",
    "                                                          np.array(smoothness_prior_std) * np.eye(num_links))\n",
    "        self._target_likelihood = multivariate_normal(self.target, likelihood_std * np.eye(2))\n",
    "\n",
    "    def reward(self, samples: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Calculates the reward for the given angles. Good angle configurations are those that\n",
    "        * reach the target/have a high target (log) likelihood\n",
    "        * are smooth/have a high smoothness (log) likelihood\n",
    "        :param samples: An array of shape (..., num_angles) to evaluate\n",
    "        :return: An array of shape (...), where each entry corresponds to the reward of the\n",
    "          corresponding sample. Higher values are better.\n",
    "        \"\"\"\n",
    "        samples = self.angle_normalize(samples)\n",
    "        end_effector_position = self.forward_kinematic(joint_angles=samples)[..., -1, :]\n",
    "        target_likelihood = self._target_likelihood.logpdf(end_effector_position[..., 0:])\n",
    "        smoothness_likelihood = self._smoothness_likelihood.logpdf(samples)\n",
    "        return np.squeeze(target_likelihood + smoothness_likelihood)\n",
    "\n",
    "    @staticmethod\n",
    "    def forward_kinematic(joint_angles: Union[List[np.array], np.array]) -> Union[List[np.array], np.array]:\n",
    "        \"\"\"\n",
    "        Calculates the forward kinematic of the robot by interpreting each input value as an angle\n",
    "\n",
    "        :param joint_angles: The angles of the joints. Can be of arbitrary shape, as long as the last dimension is over\n",
    "            the relative angles of the robot. I.e., the shape is (..., angles)\n",
    "        :return: The positions as an array of shape (..., #angles, 2), where the last dimension is the x and y position of\n",
    "         each angle.\n",
    "        \"\"\"\n",
    "        angles = np.cumsum(joint_angles, axis=-1)\n",
    "        pos = np.zeros([*angles.shape[:-1], angles.shape[-1] + 1, 2])\n",
    "        for i in range(angles.shape[-1]):\n",
    "            pos[..., i + 1, 0] = pos[..., i, 0] + np.cos(angles[..., i])\n",
    "            pos[..., i + 1, 1] = pos[..., i, 1] + np.sin(angles[..., i])\n",
    "        return pos\n",
    "\n",
    "    @staticmethod\n",
    "    def angle_normalize(angles: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Normalizes the angles to be in [-pi, pi]\n",
    "        :param angles: Unnormalized input angles\n",
    "        :return: Normalized angles\n",
    "        \"\"\"\n",
    "        return ((angles + np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "    def render(self, samples: np.array, iteration: int = 0):\n",
    "        plt.gca().add_patch(Rectangle(xy=(-0.1, -0.6), width=0.1, height=1.2, facecolor=\"grey\", alpha=1, zorder=100))\n",
    "        plt.xlabel(r\"$x$\")\n",
    "        plt.ylabel(r\"$y$\")\n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim([-0.6 * self._num_links, 1.1 * self._num_links])\n",
    "        axes.set_ylim([-0.7 * self._num_links, 0.7 * self._num_links])\n",
    "        axes.set_aspect(aspect=\"equal\")\n",
    "\n",
    "        rewards = self.reward(samples=samples)\n",
    "        angles = self.forward_kinematic(joint_angles=samples)\n",
    "        for reward, configuration in zip(rewards, angles):\n",
    "            plt.plot(configuration[:, 0], configuration[:, 1], 'o-', markerfacecolor='k', alpha=0.75,\n",
    "                     label=f\"{reward:.3e}\")\n",
    "        plt.scatter(self.target[0], self.target[1], c=\"r\", marker=\"x\", s=100)\n",
    "        plt.legend(loc=\"upper left\", ncol=2)\n",
    "        plt.title(f\"Point Reacher samples and reward at iteration {iteration}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian\n",
    "\n",
    "The next code cell defines a Gaussian class containing the utility functions that are needed for the MORE algorithm.\n",
    "You do **not** need to implement anything here, but should have a rough understanding of what the individual parameters\n",
    "and functions do."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "    \"\"\"\n",
    "    A multivariate Gaussian with a full covariance matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean: np.array, covariance: np.array):\n",
    "        if len(mean.shape) < 2:\n",
    "            mean = np.atleast_2d(mean).reshape([-1, 1])\n",
    "        self.task_dimension = mean.shape[0]\n",
    "        self.mean = mean\n",
    "        self.covariance = covariance\n",
    "\n",
    "        self.precision = None  # precision of q\n",
    "        self.chol_prec = None  # cholesky of the precision\n",
    "        self.natural_mean = None  # canonical mean parameter of q\n",
    "        self.log_det = None  # log determinant\n",
    "        self.chol_cov = None  # cholesky of the covariant\n",
    "\n",
    "        self.update_params(mean, covariance)\n",
    "\n",
    "        # precompute constant value\n",
    "        self._log_2_pi_k = self.task_dimension * (np.log(2 * np.pi))\n",
    "\n",
    "    def update_params(self, mean: np.array, covariance: np.array) -> None:\n",
    "        if len(mean.shape) < 2:\n",
    "            mean = np.atleast_2d(mean).reshape([-1, 1])\n",
    "        self.mean = mean\n",
    "        self.covariance = covariance\n",
    "\n",
    "        self.chol_cov = np.linalg.cholesky(self.covariance)\n",
    "        inv_chol_cov = np.linalg.inv(self.chol_cov)  # cholesky of precision of q\n",
    "        self.precision = inv_chol_cov.T @ inv_chol_cov\n",
    "        self.chol_prec = np.linalg.cholesky(self.precision)\n",
    "        self.natural_mean = self.precision @ self.mean\n",
    "        self.log_det = 2 * np.sum(np.log(np.diag(self.chol_cov)))\n",
    "\n",
    "    def sample(self, n_samples: int):\n",
    "        z = np.random.normal(size=(n_samples, self.task_dimension)).T\n",
    "        x = self.mean + self.chol_cov @ z\n",
    "        return x.T\n",
    "\n",
    "    @property\n",
    "    def entropy(self) -> float:\n",
    "        \"\"\"\n",
    "        Compute entropy in closed form\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return 0.5 * (self.task_dimension + self._log_2_pi_k + self.log_det)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **TASK 1: Quadratic Surrogate Model** (2+1=3 Points)\n",
    "\n",
    "MORE uses a quadratic surrogate model to approximately fit the target function in the local area of its search\n",
    "distribution.\n",
    "The surrogate model is fit using least-squares regression.\n",
    "\n",
    "This surrogate is simple enough to allow for a closed-form update of the search distribution, while still allowing\n",
    "for an expressive feedback that is sufficiently similar to the original (and unknown) reward function.\n",
    "\n",
    "### Task 1.1: Whitening (2 Points)\n",
    "The surrogate is fit on samples from the search distribution as inputs, and target function evaluations as targets.\n",
    "For stability purposes, the samples/inputs are [whitened](https://en.wikipedia.org/wiki/Whitening_transformation)\n",
    "before the fit, i.e., they are linearly transformed such that their mean is $\\mathbf{0}$ and\n",
    "their covariance the identity matrix $I$. Your first task is to implement this whitening.\n",
    "Hint: You can use `np.cov(rowvar=False)` to get the covariance of a list of samples,\n",
    "`np.linalg.cholesky()` for the cholesky decomposition of a covariance matrix and `np.linalg.inv()` to get a matrix inverse\n",
    "Hint 2: Remember to subtract the mean of the samples\n",
    "\n",
    "### Task 1.2: Fitting the surrogate (1 Point)\n",
    "After the data is preprocessed, fitting the surrogate is a comparatively simple least squares regression. To implement\n",
    "this regression, you can use the `np.linalg.solve()` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class QuadraticModel:\n",
    "    def __init__(self, dimension: int):\n",
    "        self.dimension = dimension\n",
    "\n",
    "        self._quadratic_term = np.eye(self.dimension)\n",
    "        self._linear_term = np.zeros(shape=(self.dimension, 1))\n",
    "\n",
    "        self.dim_tri = int(self.dimension * (self.dimension + 1) / 2)\n",
    "        self.model_dim = 1 + self.dimension + self.dim_tri\n",
    "\n",
    "        self.square_feat_lower_tri_ind = np.tril_indices(self.dimension)\n",
    "\n",
    "        self.feature_matrix = None\n",
    "        self.targets = None\n",
    "\n",
    "        self._data_mean = None\n",
    "        self._data_inverse_std = None\n",
    "\n",
    "    def preprocess_data(self, inputs: np.array, targets: np.array) -> bool:\n",
    "        if len(targets.shape) < 2:\n",
    "            targets = targets[:, None]\n",
    "\n",
    "        inputs = self.whiten(inputs)\n",
    "        self.feature_matrix = self.quadratic_features(inputs)\n",
    "        self.targets = (targets - np.mean(targets)) / (np.std(targets, ddof=1) + 1.0e-8)  # normalize targets\n",
    "        return True\n",
    "\n",
    "    def whiten(self, input: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Whiten the data, i.e., normalize their mean and variance such that the data appears to be drawn from a Gaussian\n",
    "        N(0,I)\n",
    "        :param input: Input samples.\n",
    "        :return: Whitened samples.\n",
    "        \"\"\"\n",
    "        ### TODO ### (2pts)\n",
    "        ### Your code starts here ###\n",
    "        data_mean = np.mean(input, axis=0, keepdims=True)\n",
    "        data_inverse_std = np.linalg.inv(np.linalg.cholesky(np.cov(input, rowvar=False))).T\n",
    "        input = input - data_mean\n",
    "        input = input @ data_inverse_std\n",
    "        ### Your code ends here ###\n",
    "\n",
    "        # store values for unwhitening later on\n",
    "        self._data_mean = data_mean\n",
    "        self._data_inverse_std = data_inverse_std\n",
    "\n",
    "        return input\n",
    "\n",
    "    def unwhiten_params(self, quadratic_term, linear_term, constant_term):\n",
    "        quadratic_term = self._data_inverse_std @ quadratic_term @ self._data_inverse_std.T\n",
    "        tmp_linear_term = self._data_inverse_std @ linear_term\n",
    "        linear_term = (self._data_mean @ quadratic_term).T + tmp_linear_term\n",
    "        constant_term = constant_term + self._data_mean @ (quadratic_term @ self._data_mean.T - tmp_linear_term)\n",
    "\n",
    "        return quadratic_term, linear_term, constant_term\n",
    "\n",
    "    def quadratic_features(self, inputs: np.array) -> np.array:\n",
    "        lin_feat = inputs\n",
    "        quad_feat = np.transpose((inputs[:, :, None] @ inputs[:, None, :]),\n",
    "                                 [1, 2, 0])[self.square_feat_lower_tri_ind].T\n",
    "\n",
    "        feature_matrix = np.hstack([np.ones([inputs.shape[0], 1]), lin_feat, quad_feat])  # c + bx + ax**2\n",
    "        return feature_matrix\n",
    "\n",
    "    def fit(self, inputs: np.array, targets: np.array) -> bool:\n",
    "        \"\"\"\n",
    "        Fit the quadratic model on the inputs and targets\n",
    "        \"\"\"\n",
    "        success = self.preprocess_data(inputs, targets)\n",
    "        if not success:\n",
    "            return False\n",
    "\n",
    "        feature_matrix = self.feature_matrix\n",
    "        targets = self.targets\n",
    "\n",
    "        regularization_matrix = np.eye(self.model_dim) * 1e-10\n",
    "        regularization_matrix[0, 0] = 0\n",
    "        # we add an additional regularization term to the result of the matrix multiplications related to the feature\n",
    "        # matrix for numerical stability. See solution for ridge regression in the literature\n",
    "\n",
    "        ### TODO ### (1pts)\n",
    "        ### Your code starts here ###\n",
    "        parameters = np.linalg.solve(feature_matrix.T @ feature_matrix + regularization_matrix,\n",
    "                                     feature_matrix.T @ targets)\n",
    "        ### Your code ends here ###\n",
    "\n",
    "        self._quadratic_term, self._linear_term = self.postprocess_params(parameters)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def postprocess_params(self, parameters: np.array) -> Tuple[np.array, np.array]:\n",
    "        quadratic_term = np.zeros((self.dimension, self.dimension))\n",
    "        triangular_part = parameters[self.dimension + 1:].flatten()\n",
    "        quadratic_term[self.square_feat_lower_tri_ind] = triangular_part\n",
    "        quadratic_term = - (quadratic_term + quadratic_term.T)\n",
    "\n",
    "        linear_term = parameters[1:self.dimension + 1]\n",
    "\n",
    "        return quadratic_term, linear_term\n",
    "\n",
    "    @property\n",
    "    def parameters(self) -> Tuple[np.array, np.array]:\n",
    "        return self._quadratic_term, self._linear_term"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Task 2: Updating the natural parameters** (3 Points)\n",
    "\n",
    "We update the natural parameters of the search distribution using the equations of Slide Set 8, Slide 33. At iteration\n",
    "k, we update the mean and covariance using\n",
    "\n",
    "\\begin{align*}\n",
    "\\Sigma_{k+1} = \\left(\\frac{{\\eta} \\Sigma_{k}^{-1} +  A}{{\\eta} + {\\omega}}\\right)^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\vec \\mu_{k+1} = \\Sigma_{k+1} \\left(\\frac{{\\eta} \\Sigma_{k}^{-1} \\mu_k + a}{{\\eta}+ {\\omega}} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where we use $\\omega$ instead of the $\\kappa$ used in the slides for consistency with the code.\n",
    "As most of the operations needed for MORE\n",
    "are in the natural parameter space of the Gaussian, we update the **natural mean** ($=\\Sigma^{-1} \\mu$) and the\n",
    " **precision** ($=\\Sigma^{-1}$) rather than the \"regular\" mean and variance.\n",
    "\n",
    "Hint: Updating the parameters in natural space simplifies these equations. You only need to implement this simplified\n",
    "version."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def new_natural_params(eta: float, omega: float, old_distribution: Gaussian, model: QuadraticModel):\n",
    "    \"\"\"\n",
    "    Compute the new natural parameters (the natural mean and the precision) of the search distribution\n",
    "    using the optimal dual variables and the old distribution.\n",
    "    :param eta: Solution for the dual eta\n",
    "    :param omega: Solution for the dual omega\n",
    "    :param old_distribution: Old search distribution\n",
    "    :param model: The quadratic surrogate model that is used to fit the distribution\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ### TODO ### (3pts)\n",
    "    ### Your code starts here ###\n",
    "    quadratic_parameters, linear_parameters = model.parameters\n",
    "    natural_mean = (eta * old_distribution.natural_mean + linear_parameters) / (eta + omega)  # natural mean of pi\n",
    "    precision = (eta * old_distribution.precision + quadratic_parameters) / (eta + omega)  # precision of pi\n",
    "    ### Your code ends here ###\n",
    "\n",
    "    return natural_mean, precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MORE\n",
    "### **Task 3: Deriving the MORE equations** (9 Points)\n",
    "Here we are going to derive the primal solution of the optimization problem underlying the Model-based Relative Entropy Stochastic Search Approach (MORE).\n",
    "Recall that the MORE optimization problem is given as\n",
    "\\begin{align}\n",
    "    \\underset{\\boldsymbol{\\omega}}{\\textrm{argmax}} \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})g(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta} \\quad \\textrm{s.t.} \\quad \\textrm{KL}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) || p_{\\textrm{old}}(\\boldsymbol{\\theta})) \\leq \\epsilon, \\quad \\textrm{H}(p_{\\textrm{old}}(\\boldsymbol{\\theta})) - \\textrm{H}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})) \\leq \\gamma, \\quad \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) d \\boldsymbol{\\theta} = 1.\n",
    "\\end{align}\n",
    "As a first simplification we can rewrite this objective as\n",
    "\\begin{align}\n",
    "    \\underset{\\boldsymbol{\\omega}}{\\textrm{argmax}} \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})g(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta} \\quad \\textrm{s.t.} \\quad \\textrm{KL}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) || p_{\\textrm{old}}(\\boldsymbol{\\theta})) \\leq \\epsilon, \\quad \\textrm{H}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})) \\geq \\beta, \\quad \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) d \\boldsymbol{\\theta}=1,\n",
    "\\end{align}\n",
    "with $\\beta = \\textrm{H}(p_{\\textrm{old}}(\\boldsymbol{\\theta})) - \\gamma$.\n",
    "\n",
    "Denoting the Lagrangian multipliers for the KL and Entropy constraint by $\\eta$ and $\\kappa$ respectivly, show that\n",
    "\\begin{align}\n",
    "    p_{\\boldsymbol{\\omega}^*}(\\boldsymbol{\\theta}) \\propto p_{\\textrm{old}}(\\boldsymbol{\\theta})^{\\frac{\\eta}{\\eta + \\kappa}} \\exp\\left( \\dfrac{g(\\boldsymbol{\\theta})}{\\eta + \\kappa} \\right).\n",
    "\\end{align}\n",
    "Note that $p_{\\boldsymbol{\\omega}^*}(\\boldsymbol{\\theta})$ is the optimal solution to the optimization\n",
    "problem depending on the duals $\\eta$ and $\\kappa$\n",
    "\n",
    "Hint: The parameter $\\kappa$ used in the equations is called $\\omega$ in the code.\n",
    "The $\\omega$ parameter in the equations does not have a direct code equivalent.\n",
    "\n",
    "### Solution\n",
    "The solution is more or less (without the entropy constraint) in the Trust Region slides.\n",
    "To compute the update formulas and the dual we start by deriving the Lagrangian:\n",
    "\\begin{align}\n",
    "\\mathcal{L}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}), \\eta, \\kappa, \\lambda) \\nonumber& \\\\\n",
    "= \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) g(\\boldsymbol{\\theta})d\\theta + \\eta \\left(\\epsilon - \\textrm{KL}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) || p_{\\textrm{old}}(\\boldsymbol{\\theta})) \\right) + \\kappa \\left(\\textrm{H}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})) - \\beta \\right) + \\lambda \\left( 1 - \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})d\\theta \\right) \\\\\n",
    "= \\eta\\epsilon - \\kappa\\beta + \\lambda  + \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) g(\\boldsymbol{\\theta})d\\theta - \\eta \\textrm{KL}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) || p_{\\textrm{old}}(\\boldsymbol{\\theta})) + \\kappa \\textrm{H}(p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})) - \\lambda \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})d\\theta \\nonumber \\\\\n",
    "= \\eta\\epsilon - \\kappa\\beta + \\lambda  + \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) \\left( g(\\boldsymbol{\\theta}) - \\eta\\left(\\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) - \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) \\right) - \\kappa \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) - \\lambda \\right) d\\theta \\nonumber \\\\\n",
    "= \\eta\\epsilon - \\kappa\\beta + \\lambda  + \\int p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) \\left( g(\\boldsymbol{\\theta}) - (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) + \\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) - \\lambda \\right) d\\theta. \\label{eq:marg:lagrangian_simplified}\n",
    "\\end{align}\n",
    "\n",
    "Derivative w.r.t. $p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})$\n",
    "\n",
    "\\begin{align}\n",
    "\\dfrac{\\partial \\mathcal{L}}{\\partial p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})} &= \\int \\dfrac{\\partial}{\\partial p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})} p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})  \\left( g(\\boldsymbol{\\theta}) - (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) + \\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) - \\lambda \\right) d\\theta \\\\\n",
    "&=\\int  \\left(  p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})\\dfrac{-(\\eta + \\kappa)}{p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})} +  g(\\boldsymbol{\\theta}) - (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) + \\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) - \\lambda \\right) d\\theta \\\\\n",
    "&=\\int  -(\\eta + \\kappa + \\lambda) +  g(\\boldsymbol{\\theta}) - (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) + \\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) d\\theta.\n",
    "\\end{align}\n",
    "\n",
    "Setting the derivative to $0$\n",
    "\n",
    "\\begin{align*}\n",
    "& -(\\eta + \\kappa + \\lambda) +  g(\\boldsymbol{\\theta}) - (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) + \\eta  \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) \\overset{!}{=} 0 \\nonumber \\\\\n",
    "\\Leftrightarrow &  (\\eta + \\kappa) \\log p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) = -(\\eta + \\kappa + \\lambda) +  g(\\boldsymbol{\\theta})  + \\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}). \\label{eq:marg:d1}\n",
    "\\end{align*}\n",
    "Thus, the optimal $p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta})$ given by\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\boldsymbol{\\omega}}(\\boldsymbol{\\theta}) &= \\exp \\left(- \\dfrac{\\eta + \\kappa + \\lambda}{\\eta + \\kappa} \\right) \\exp \\left( \\dfrac{g(\\boldsymbol{\\theta})}{\\eta + \\kappa} \\right) p_{\\textrm{old}}(\\boldsymbol{\\theta})^{\\dfrac{\\eta}{\\eta + \\kappa}} \\nonumber \\\\\n",
    "& \\propto \\exp \\left( \\dfrac{g(\\boldsymbol{\\theta})}{\\eta + \\kappa} \\right) p_{\\textrm{old}}(\\boldsymbol{\\theta})^{\\dfrac{\\eta}{\\eta + \\kappa}} \\nonumber \\\\\n",
    "& = \\exp \\left(\\dfrac{\\eta \\log p_{\\textrm{old}}(\\boldsymbol{\\theta}) + g(\\boldsymbol{\\theta})}{\\eta + \\kappa} \\right)\n",
    "\\end{align}\n",
    "\n",
    "### Code\n",
    "The code below implements the MORE algorithm. The heavy lifting of the algorithm is done by the nlopt package, which\n",
    "is used for the optimization of the convex dual of the MORE problem.\n",
    "In essence, MORE is a stochastic search algorithm with built-in entropy control, and as its optimization problem is a\n",
    "constrained optimization that aims to improve the search distribution while maintaining its entropy and not having it\n",
    "move to far per iteration.\n",
    "This behavior is explained in the trust region slides of Slide Set 6, as well as Slides 23ff and 31ff of Slide Set 8.\n",
    "\n",
    "As the algorithm is not explcitly mentioned in the lecture, you will again **not** need to implement anything here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MORE:\n",
    "    def __init__(self, task_dimension: int, kl_bound: float):\n",
    "        self.task_dimension = task_dimension\n",
    "        self.kl_bound = kl_bound\n",
    "\n",
    "        self.gamma = 0.99\n",
    "        self.beta_0 = 0.1\n",
    "        self.eta_0 = 10\n",
    "        self.omega_0 = 10\n",
    "        self.h_0 = -50  # minimum entropy of the search distribution\n",
    "\n",
    "        self._default_eta = 10\n",
    "        self._default_omega = 10\n",
    "        self._grad_bound = 1e-5\n",
    "\n",
    "        self.opt = self._get_dual_optimizer()\n",
    "\n",
    "        # constant values\n",
    "        self._log_2_pi_k = self.task_dimension * (np.log(2 * np.pi))\n",
    "        self._entropy_const = self.task_dimension * (np.log(2 * np.pi) + 1)\n",
    "\n",
    "        # cached values\n",
    "        self.beta = None\n",
    "        self._eta = 1\n",
    "        self._omega = 1\n",
    "        self._old_term = None\n",
    "        self._old_dist = None\n",
    "        self._current_model = None\n",
    "        self._dual = np.inf\n",
    "        self._grad = np.zeros(2)\n",
    "        self.kl_divergence = np.inf\n",
    "        self._new_entropy = np.inf\n",
    "        self._new_mean = None\n",
    "        self._new_cov = None\n",
    "\n",
    "    def _get_dual_optimizer(self):\n",
    "        \"\"\"\n",
    "        Setting up NLOpt optimizer for the dual optimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        opt = nlopt.opt(nlopt.LD_LBFGS, 2)\n",
    "        opt.set_lower_bounds((1e-20, 1e-20))\n",
    "        opt.set_upper_bounds((np.inf, np.inf))\n",
    "        opt.set_ftol_abs(1e-12)\n",
    "        opt.set_ftol_rel(1e-12)\n",
    "        opt.set_xtol_abs(1e-12)\n",
    "        opt.set_xtol_rel(1e-12)\n",
    "        opt.set_maxeval(1000)\n",
    "        opt.set_maxtime(5 * 60 * 60)\n",
    "\n",
    "        def opt_func(x, grad):\n",
    "            dual_value = self.dual_and_grad(x, grad)\n",
    "            if np.isinf(dual_value):\n",
    "                opt.set_lower_bounds((float(x[0]), 1e-20))\n",
    "            return float(dual_value.flatten())\n",
    "\n",
    "        opt.set_min_objective(opt_func)\n",
    "        return opt\n",
    "\n",
    "    def step(self, old_dist, surrogate):\n",
    "        \"\"\"\n",
    "        Given an old distribution and a model object, perform one MORE iteration\n",
    "        :param old_dist: Distribution object\n",
    "        :param surrogate: quadratic model object\n",
    "        :return: new distribution parameters and success variables\n",
    "        \"\"\"\n",
    "        self.beta = self.gamma * (old_dist.entropy - self.h_0) + self.h_0  # set entropy constraint\n",
    "\n",
    "        self._old_term = old_dist.log_det + old_dist.mean.T @ old_dist.natural_mean\n",
    "        self._old_dist = old_dist\n",
    "        self._current_model = surrogate\n",
    "\n",
    "        self.opt.set_lower_bounds((1e-20, 1e-20))\n",
    "        eta, omega, success = self.dual_opt()\n",
    "\n",
    "        if success:\n",
    "            self.eta_0 = self._eta\n",
    "            self.omega_0 = self._omega\n",
    "            return self._new_mean, self._new_cov, True\n",
    "        else:\n",
    "            # in some cases, the optimization may fail due to numerical issues.\n",
    "            # In this case, we use default values and try again in the next iteration.\n",
    "            self.eta_0 = self._default_eta\n",
    "            self.omega_0 = self._default_omega\n",
    "            return old_dist.mean, old_dist.covariance, False\n",
    "\n",
    "    def dual_opt(self):\n",
    "        success_kl = False\n",
    "        success_entropy = False\n",
    "        try:\n",
    "            eta, omega = self.opt.optimize(np.hstack([self.eta_0, self.omega_0]))\n",
    "            opt_val = self.opt.last_optimum_value()\n",
    "        except (RuntimeError, nlopt.ForcedStop, nlopt.RoundoffLimited) as e:\n",
    "            eta = self._eta\n",
    "            omega = self._omega\n",
    "            opt_val = self._dual\n",
    "        if ~np.isinf(opt_val):\n",
    "            if self.kl_divergence < 1.1 * self.kl_bound:\n",
    "                success_kl = True\n",
    "\n",
    "            if self._new_entropy > 0:\n",
    "                if self._new_entropy > 0.9 * self.beta:\n",
    "                    success_entropy = True\n",
    "            else:\n",
    "                if self._new_entropy > 1.1 * self.beta:\n",
    "                    success_entropy = True\n",
    "        success = success_kl and success_entropy\n",
    "\n",
    "        return eta, omega, success\n",
    "\n",
    "    def dual_and_grad(self, x, grad):\n",
    "        \"\"\"\n",
    "        This is where the magic happens! We build and solve the dual function using a lot of mathematical tricks.\n",
    "        This function is used by the convex optimizer (NLOpt) to figure out the right values for the next update.\n",
    "        While it may seem threatening, it closely follows the MORE derivations of the exercise above.\n",
    "        :param x:\n",
    "        :param grad:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        eta = x[0]\n",
    "        omega = x[1]\n",
    "        self._eta = eta\n",
    "        self._omega = omega\n",
    "\n",
    "        new_lin, new_prec = new_natural_params(eta, omega, self._old_dist, self._current_model)\n",
    "\n",
    "        try:\n",
    "            kl_bound = self.kl_bound\n",
    "            beta = self.beta\n",
    "            log_2_pi_k = self._log_2_pi_k\n",
    "            old_term = self._old_term\n",
    "\n",
    "            chol_new_precision = np.linalg.cholesky(new_prec)\n",
    "            inv_chol_new_precision = np.linalg.inv(chol_new_precision)\n",
    "\n",
    "            new_cov = inv_chol_new_precision.T @ inv_chol_new_precision\n",
    "            new_mean = new_cov @ new_lin\n",
    "\n",
    "            chol_new_covariance = np.linalg.cholesky(new_cov)\n",
    "            # compute log(det(Sigma_pi))\n",
    "            new_log_det = 2 * np.sum(np.log(np.diag(chol_new_covariance)))\n",
    "\n",
    "            dual_value = eta * kl_bound - omega * beta + 0.5 * (omega * log_2_pi_k\n",
    "                                                                - eta * old_term\n",
    "                                                                + (eta + omega) * (new_log_det + new_mean.T @ new_lin)\n",
    "                                                                )\n",
    "\n",
    "            mahalanobis_distance = np.sum((self._old_dist.chol_prec.T @ (self._old_dist.mean - new_mean)) ** 2)\n",
    "            trace_term = np.sum(np.square(self._old_dist.chol_prec.T @ chol_new_covariance))\n",
    "\n",
    "            kl_divergence = 0.5 * (mahalanobis_distance\n",
    "                                   + self._old_dist.log_det\n",
    "                                   - new_log_det\n",
    "                                   + trace_term\n",
    "                                   - self.task_dimension)\n",
    "\n",
    "            entropy = 0.5 * (new_log_det + self._log_2_pi_k + self.task_dimension)\n",
    "\n",
    "            grad[0] = self.kl_bound - float(kl_divergence)\n",
    "            grad[1] = entropy - self.beta\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Skip the update if it fails due to numerical issues. We can then try again at the next iteration\n",
    "            dual_value = np.atleast_1d(np.inf)\n",
    "            kl_divergence = np.inf\n",
    "            entropy = -np.inf\n",
    "            new_mean = self._old_dist.mean\n",
    "            new_cov = self._old_dist.covariance\n",
    "            grad[0] = -0.1\n",
    "            grad[1] = 0.\n",
    "\n",
    "        self._dual = dual_value\n",
    "        self.kl_divergence = kl_divergence\n",
    "        self._new_entropy = entropy\n",
    "        self._new_mean = new_mean\n",
    "        self._new_cov = new_cov\n",
    "        self._grad = grad\n",
    "        return dual_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running the algorithm\n",
    "\n",
    "As usual, this last part of the exercise defines arguments/hyperparameters, as well as a general training loop. You do\n",
    "*not* need to change any code here (unless you want to fiddle with the parameters). If everything is implemented\n",
    "correctly, you should see training improvements almost immediately and convergence after a couple thousand steps.\n",
    "The code will save\n",
    "* a couple of training metrics,\n",
    "* visualizations of $10$ random search distribution for the point reaching task, along with their reward evaluation\n",
    "\n",
    "For the homework, you only need to send in the last visualization, i.e., the one at Iteration 4092, but you can also\n",
    "turn in all of the plots as usual."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "class Args:\n",
    "\n",
    "    # Boilerplate for properly accessing the args\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "\n",
    "    num_links = 5  # @param {type: \"integer\"}\n",
    "    num_iterations = 5000  # @param {type: \"integer\"}\n",
    "    samples_per_iteration = 512  # @param {type: \"integer\"}\n",
    "    kl_bound = 0.2 # @param {type: \"number\"}\n",
    "\n",
    "\n",
    "def main(args: Args):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    kl_bound = args.kl_bound\n",
    "    num_links = args.num_links\n",
    "    num_iterations = args.num_iterations\n",
    "    samples_per_iteration = args.samples_per_iteration\n",
    "\n",
    "    smoothness_prior = [1.0] + [0.04] * (num_links - 1)\n",
    "    reacher = PointReacher(num_links=num_links, likelihood_std=1.0e-4,\n",
    "                           smoothness_prior_std=smoothness_prior)\n",
    "\n",
    "    search_dist = Gaussian(mean=np.zeros(num_links), covariance=smoothness_prior * np.eye(num_links))\n",
    "    surrogate = QuadraticModel(dimension=num_links)\n",
    "    more = MORE(task_dimension=num_links, kl_bound=kl_bound)\n",
    "\n",
    "    progress_bar = ProgressBar(num_iterations=num_iterations)\n",
    "\n",
    "    full_metrics = {\"mean_reward\": [],\n",
    "                    \"kl_change\": [],\n",
    "                    \"entropy\": []}\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        if iteration == 0 or 2 ** round(np.log2(iteration)) == iteration:\n",
    "            # plot for each power of 2. This gives a lot of plots early on, when the distribution still changes\n",
    "            # quickly, and eventually slows down when near convergence\n",
    "\n",
    "            plot_samples = search_dist.sample(10)\n",
    "            reacher.render(samples=plot_samples, iteration=iteration)\n",
    "            save_figure(save_name=f\"point_reacher_kl={kl_bound}_iteration={iteration:04d}\")\n",
    "            plot_metrics(full_metrics)\n",
    "\n",
    "        samples = search_dist.sample(samples_per_iteration)\n",
    "\n",
    "        rewards = reacher.reward(samples)\n",
    "\n",
    "        success = surrogate.fit(samples, rewards)\n",
    "        if not success:\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "\n",
    "        new_mean, new_cov, success = more.step(search_dist, surrogate)\n",
    "\n",
    "        if success:\n",
    "            try:\n",
    "                search_dist.update_params(new_mean, new_cov)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        mean_reward = reacher.reward(search_dist.mean.T)\n",
    "\n",
    "        # logging utility\n",
    "        progress_bar(mean_reward=mean_reward, kl_change=more.kl_divergence, entropy=search_dist.entropy)\n",
    "        full_metrics[\"mean_reward\"].append(mean_reward)\n",
    "        full_metrics[\"kl_change\"].append(more.kl_divergence)\n",
    "        full_metrics[\"entropy\"].append(search_dist.entropy)\n",
    "\n",
    "args = Args()\n",
    "main(args=args)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eQx7oDGeeKWj"
   ],
   "name": "2_dqn_atari.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}